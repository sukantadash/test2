{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f42f204-6c03-4bf8-98c8-6d1f1431ba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_stack in /opt/app-root/lib64/python3.12/site-packages (0.2.20)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (3.12.14)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.116.1)\n",
      "Requirement already satisfied: fire in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.7.1)\n",
      "Requirement already satisfied: httpx in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.34.4)\n",
      "Requirement already satisfied: jinja2>=3.1.6 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (3.1.6)\n",
      "Requirement already satisfied: jsonschema in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (4.24.0)\n",
      "Requirement already satisfied: llama-stack-client>=0.2.20 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.2.20)\n",
      "Requirement already satisfied: llama-api-client>=0.1.2 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.3.0)\n",
      "Requirement already satisfied: openai<1.100.0,>=1.99.6 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (1.99.9)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (3.0.51)\n",
      "Requirement already satisfied: python-dotenv in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (1.1.1)\n",
      "Requirement already satisfied: python-jose[cryptography] in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (3.5.0)\n",
      "Requirement already satisfied: pydantic>=2 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (2.11.7)\n",
      "Requirement already satisfied: rich in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (14.1.0)\n",
      "Requirement already satisfied: starlette in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.47.3)\n",
      "Requirement already satisfied: termcolor in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.11.0)\n",
      "Requirement already satisfied: pillow in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (11.3.0)\n",
      "Requirement already satisfied: h11>=0.16.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.16.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.20 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.0.20)\n",
      "Requirement already satisfied: uvicorn>=0.34.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (1.36.0)\n",
      "Requirement already satisfied: aiosqlite>=0.21.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.21.0)\n",
      "Requirement already satisfied: asyncpg in /opt/app-root/lib64/python3.12/site-packages (from llama_stack) (0.30.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /opt/app-root/lib64/python3.12/site-packages (from aiosqlite>=0.21.0->llama_stack) (4.14.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (2025.7.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->llama_stack) (1.1.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2>=3.1.6->llama_stack) (3.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from llama-api-client>=0.1.2->llama_stack) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/app-root/lib64/python3.12/site-packages (from llama-api-client>=0.1.2->llama_stack) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from llama-api-client>=0.1.2->llama_stack) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx->llama_stack) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx->llama_stack) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib64/python3.12/site-packages (from httpx->llama_stack) (3.10)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client>=0.2.20->llama_stack) (8.2.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client>=0.2.20->llama_stack) (2.3.2)\n",
      "Requirement already satisfied: pyaml in /opt/app-root/lib64/python3.12/site-packages (from llama-stack-client>=0.2.20->llama_stack) (25.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/app-root/lib64/python3.12/site-packages (from openai<1.100.0,>=1.99.6->llama_stack) (0.10.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.15 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (1.36.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-proto==1.36.0->opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (6.32.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-sdk>=1.30.0->llama_stack) (0.57b0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/app-root/lib64/python3.12/site-packages (from opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (8.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic>=2->llama_stack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/app-root/lib64/python3.12/site-packages (from pydantic>=2->llama_stack) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic>=2->llama_stack) (0.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp->llama_stack) (1.20.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema->llama_stack) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema->llama_stack) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/app-root/lib64/python3.12/site-packages (from jsonschema->llama_stack) (0.26.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama_stack) (0.2.13)\n",
      "Requirement already satisfied: ecdsa!=0.15 in /opt/app-root/lib64/python3.12/site-packages (from python-jose[cryptography]->llama_stack) (0.19.1)\n",
      "Requirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /opt/app-root/lib64/python3.12/site-packages (from python-jose[cryptography]->llama_stack) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.5.0 in /opt/app-root/lib64/python3.12/site-packages (from python-jose[cryptography]->llama_stack) (0.6.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /opt/app-root/lib64/python3.12/site-packages (from python-jose[cryptography]->llama_stack) (45.0.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack) (2.19.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/app-root/lib64/python3.12/site-packages (from tiktoken->llama_stack) (2025.8.29)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/app-root/lib64/python3.12/site-packages (from cryptography>=3.4.0->python-jose[cryptography]->llama_stack) (1.17.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/app-root/lib64/python3.12/site-packages (from ecdsa!=0.15->python-jose[cryptography]->llama_stack) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack) (0.1.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.34.0->llama_stack) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.34.0->llama_stack) (2.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama-stack-client>=0.2.20->llama_stack) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama-stack-client>=0.2.20->llama_stack) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama-stack-client>=0.2.20->llama_stack) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama-stack-client>=0.2.20->llama_stack) (2025.2)\n",
      "Requirement already satisfied: pycparser in /opt/app-root/lib64/python3.12/site-packages (from cffi>=1.14->cryptography>=3.4.0->python-jose[cryptography]->llama_stack) (2.22)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/app-root/lib64/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.15->opentelemetry-exporter-otlp-proto-http>=1.30.0->llama_stack) (3.23.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2ada302-1ce0-47d0-8c4e-da8fc3a43978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama_stack_client in /opt/app-root/lib64/python3.12/site-packages (0.2.20)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (4.9.0)\n",
      "Requirement already satisfied: click in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (8.2.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (1.9.0)\n",
      "Requirement already satisfied: fire in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (0.7.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (0.28.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (2.3.2)\n",
      "Requirement already satisfied: prompt-toolkit in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (3.0.51)\n",
      "Requirement already satisfied: pyaml in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (25.7.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (2.11.7)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (2.32.4)\n",
      "Requirement already satisfied: rich in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (14.1.0)\n",
      "Requirement already satisfied: sniffio in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (1.3.1)\n",
      "Requirement already satisfied: termcolor in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (3.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/app-root/lib64/python3.12/site-packages (from llama_stack_client) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from anyio<5,>=3.5.0->llama_stack_client) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->llama_stack_client) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->llama_stack_client) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/app-root/lib64/python3.12/site-packages (from pydantic<3,>=1.9.0->llama_stack_client) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas->llama_stack_client) (2025.2)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.12/site-packages (from prompt-toolkit->llama_stack_client) (0.2.13)\n",
      "Requirement already satisfied: PyYAML in /opt/app-root/lib64/python3.12/site-packages (from pyaml->llama_stack_client) (6.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests->llama_stack_client) (2.5.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib64/python3.12/site-packages (from rich->llama_stack_client) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib64/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->llama_stack_client) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama_stack_client) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llama_stack_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cf9a3c7-9172-445e-9eab-5a23cb1aca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_stack_client import RAGDocument, LlamaStackClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be7a5867-ffd4-46ad-80f3-0d68d3137e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = LlamaStackClient(base_url=\"http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a1af934-4829-4c5d-a336-8aad067b366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_stack_client._base_client:Retrying request to /v1/models in 0.480726 seconds\n",
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "models = client.models.list()\n",
    "model_id = next(m.identifier for m in models if m.model_type == \"llm\")\n",
    "\n",
    "embedding_model = next(m for m in models if m.model_type == \"embedding\")\n",
    "embedding_model_id = embedding_model.identifier\n",
    "embedding_dimension = embedding_model.metadata[\"embedding_dimension\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34b48ea5-5c99-4b60-a042-cb64d1c1ef3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/models \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(identifier='llama-32', metadata={}, api_model_type='llm', provider_id='vllm-inference', type='model', provider_resource_id='llama-32', model_type='llm'), Model(identifier='granite-embedding-125m', metadata={'embedding_dimension': 768.0}, api_model_type='embedding', provider_id='sentence-transformers', type='model', provider_resource_id='ibm-granite/granite-embedding-125m-english', model_type='embedding')]\n"
     ]
    }
   ],
   "source": [
    "print(client.models.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee220440-3f91-4c03-94ab-361356b4f9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/providers \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ProviderInfo(api='inference', config={'url': 'https://llama-32-ai-models.apps.cluster-xd887.xd887.sandbox73.opentlc.com:443/v1', 'max_tokens': 4096.0, 'api_token': '********', 'tls_verify': False}, health={'status': 'OK'}, provider_id='vllm-inference', provider_type='remote::vllm'), ProviderInfo(api='inference', config={}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='sentence-transformers', provider_type='inline::sentence-transformers'), ProviderInfo(api='vector_io', config={'db_path': '/opt/app-root/src/.llama/distributions/rh/milvus.db', 'kvstore': {'type': 'sqlite', 'namespace': None, 'db_path': '/opt/app-root/src/.llama/distributions/rh/milvus_registry.db'}}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='milvus', provider_type='inline::milvus'), ProviderInfo(api='safety', config={'orchestrator_url': 'http://localhost', 'ssl_cert_path': None, 'shields': {}}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='trustyai_fms', provider_type='remote::trustyai_fms'), ProviderInfo(api='agents', config={'persistence_store': {'type': 'sqlite', 'namespace': None, 'db_path': '/opt/app-root/src/.llama/distributions/rh/agents_store.db'}, 'responses_store': {'type': 'sqlite', 'db_path': '/opt/app-root/src/.llama/distributions/rh/responses_store.db'}}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='meta-reference', provider_type='inline::meta-reference'), ProviderInfo(api='eval', config={'use_k8s': True, 'base_url': 'https://llama-32-ai-models.apps.cluster-xd887.xd887.sandbox73.opentlc.com:443/v1'}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='trustyai_lmeval', provider_type='remote::trustyai_lmeval'), ProviderInfo(api='datasetio', config={'kvstore': {'type': 'sqlite', 'namespace': None, 'db_path': '/opt/app-root/src/.llama/distributions/rh/huggingface_datasetio.db'}}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='huggingface', provider_type='remote::huggingface'), ProviderInfo(api='datasetio', config={'kvstore': {'type': 'sqlite', 'namespace': None, 'db_path': '/opt/app-root/src/.llama/distributions/rh/localfs_datasetio.db'}}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='localfs', provider_type='inline::localfs'), ProviderInfo(api='scoring', config={}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='basic', provider_type='inline::basic'), ProviderInfo(api='scoring', config={}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='llm-as-judge', provider_type='inline::llm-as-judge'), ProviderInfo(api='scoring', config={'openai_api_key': '********'}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='braintrust', provider_type='inline::braintrust'), ProviderInfo(api='telemetry', config={'service_name': '\\u200b', 'sinks': 'console,sqlite', 'sqlite_db_path': '/opt/app-root/src/.llama/distributions/rh/trace_store.db', 'otel_exporter_otlp_endpoint': None}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='meta-reference', provider_type='inline::meta-reference'), ProviderInfo(api='tool_runtime', config={'api_key': '********', 'max_results': 3.0}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='brave-search', provider_type='remote::brave-search'), ProviderInfo(api='tool_runtime', config={'api_key': '********', 'max_results': 3.0}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='tavily-search', provider_type='remote::tavily-search'), ProviderInfo(api='tool_runtime', config={}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='rag-runtime', provider_type='inline::rag-runtime'), ProviderInfo(api='tool_runtime', config={}, health={'status': 'Not Implemented', 'message': 'Provider does not implement health check'}, provider_id='model-context-protocol', provider_type='remote::model-context-protocol')]\n"
     ]
    }
   ],
   "source": [
    "print(client.providers.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbdb1db8-1347-4268-b10c-f66480b1ee7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VectorDBListResponseItem(embedding_dimension=768, embedding_model='granite-embedding-125m', identifier='test_vector_db_6d632185-99e4-435d-8ada-5bb31ecf1276', provider_id='milvus', type='vector_db', provider_resource_id='test_vector_db_6d632185-99e4-435d-8ada-5bb31ecf1276', vector_db_name=None)]\n"
     ]
    }
   ],
   "source": [
    "print(client.vector_dbs.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6847ed8-2d5f-471c-8dcb-ca124f1ac3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_id = \"milvus-db\"\n",
    "provider_id  = \"milvus\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a26e766c-84ec-47b6-8110-c0bd8567f1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered vector DB: milvus-db\n"
     ]
    }
   ],
   "source": [
    "client.vector_dbs.register(\n",
    "vector_db_id=vector_db_id,\n",
    "embedding_model=embedding_model_id,\n",
    "embedding_dimension=embedding_dimension,\n",
    "provider_id=provider_id,\n",
    ")\n",
    "print(f\"Registered vector DB: {vector_db_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0533de49-a926-40e0-9a9f-e912d50791f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/vector-dbs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VectorDBListResponseItem(embedding_dimension=768, embedding_model='granite-embedding-125m', identifier='milvus-db', provider_id='milvus', type='vector_db', provider_resource_id='milvus-db', vector_db_name=None)]\n"
     ]
    }
   ],
   "source": [
    "print(client.vector_dbs.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd0bf887-6c4d-41e1-8ea2-b6d413ccee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"\n",
    "LlamaStack can embed raw text into a vector store for retrieval.\n",
    "This example ingests a small passage for demonstration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f040294c-5a61-421e-9030-04d4cc12f2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = RAGDocument(\n",
    "document_id=\"raw_text_001\",\n",
    "content=raw_text,\n",
    "mime_type=\"text/plain\",\n",
    "metadata={\"source\": \"example_passage\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68136aeb-6a7e-4505-a51b-92586ec5d566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://lsd-llama-milvus-service.llama-stack-server.svc.cluster.local:8321/v1/tool-runtime/rag-tool/insert \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text ingested successfully\n"
     ]
    }
   ],
   "source": [
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=[document],\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=100,\n",
    ")\n",
    "print(\"Raw text ingested successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "035b08db-6797-4fba-bc13-2409549db94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag_tool> Ingesting document: https://www.paulgraham.com/greatwork.html\n"
     ]
    }
   ],
   "source": [
    "source = \"https://www.paulgraham.com/greatwork.html\"\n",
    "print(\"rag_tool> Ingesting document:\", source)\n",
    "\n",
    "document = RAGDocument(\n",
    "    document_id=\"document_1\",\n",
    "    content=source,\n",
    "    mime_type=\"text/html\",\n",
    "    metadata={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa21447-8ef8-47eb-8791-41cec2e6344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.tool_runtime.rag_tool.insert(\n",
    "    documents=[document],\n",
    "    vector_db_id=vector_db_id,\n",
    "    chunk_size_in_tokens=50,\n",
    ")\n",
    "print(\"Raw text ingested successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834bc56-4a44-491a-99b5-5d8a20395d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
